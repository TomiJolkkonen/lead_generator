{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "712b25bd-1522-40d8-9ca0-8807e7fb31ab",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Get relevant Vainu data from API and save the raw JSON file into lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1cc777-8365-4fe3-a8fb-53f5965c7cb3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-03-25T08:59:24.4572119Z",
       "execution_start_time": "2025-03-25T08:54:44.6220168Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "3a3954e5-79e3-49eb-aca1-c1ca8a86bb2e",
       "queued_time": "2025-03-25T08:51:29.7686412Z",
       "session_id": "24136ad8-6b10-4a99-9846-8ee78b19a7d5",
       "session_start_time": "2025-03-25T08:51:29.7700133Z",
       "spark_pool": null,
       "state": "finished",
       "statement_id": 3,
       "statement_ids": [
        3
       ]
      },
      "text/plain": [
       "StatementMeta(, 24136ad8-6b10-4a99-9846-8ee78b19a7d5, 3, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 1000 companies, total so far: 1000\n",
      "Fetched 1000 companies, total so far: 2000\n",
      "Fetched 1000 companies, total so far: 3000\n",
      "Fetched 1000 companies, total so far: 4000\n",
      "Fetched 1000 companies, total so far: 5000\n",
      "Fetched 1000 companies, total so far: 6000\n",
      "Fetched 1000 companies, total so far: 7000\n",
      "Fetched 1000 companies, total so far: 8000\n",
      "Fetched 563 companies, total so far: 8563\n",
      "Reached the last page. Stopping...\n",
      "Data saved to lakehouse\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"VainuAPI\").getOrCreate()\n",
    "\n",
    "# Microsoft Fabric Configuration\n",
    "key_vault_url = 'your-keyvault-url'  # Replace with your Key Vault URL\n",
    "secret_name = 'your-secret-name'  # Replace with your secret name\n",
    "\n",
    "API_KEY = notebookutils.credentials.getSecret(key_vault_url, secret_name)\n",
    "\n",
    "# Vainu API Endpoint\n",
    "API_URL = \"https://api.vainu.io/api/v2/companies/\"\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"API-Key\": API_KEY,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "\n",
    "# Query variables\n",
    "cities = [\"helsinki\", \"tampere\", \"vantaa\", \"espoo\", \"oulu\", \"turku\", \"lahti\", \"jyv채skyl채\"]\n",
    "queryfields = \"company_name,business_id,city,staff_number,staff_number_estimate,career_page_job_count,description,foundation_date,lat,lng,status,vainu_custom_industry,official_industries,organization_size_indicators\"\n",
    "offset = 0              # beginning point of query\n",
    "limit = 1000            # max limit\n",
    "staff_number_gt = 9     # staff number more than\n",
    "turn_over_gte = 500000  # turnover more than\n",
    "all_results = []\n",
    "\n",
    "\n",
    "# Loop to go through all companies\n",
    "while True:\n",
    "    params = {\n",
    "        \"country\": \"FI\",\n",
    "        \"city\": cities,\n",
    "        \"fields\": queryfields,\n",
    "        \"limit\": limit,\n",
    "        \"staff_number__gt\": staff_number_gt,\n",
    "        \"turn_over__gte\": turn_over_gte,\n",
    "        \"offset\": offset\n",
    "    }\n",
    "    time.sleep(1)   \n",
    "    response = requests.get(API_URL, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        results = data.get(\"results\", [])\n",
    "\n",
    "        if not results:\n",
    "            print(\"No more data to fetch. Stopping...\")\n",
    "            break\n",
    "\n",
    "        all_results.extend(results)\n",
    "\n",
    "        print(f\"Fetched {len(results)} companies, total so far: {len(all_results)}\")\n",
    "\n",
    "        if len(results) < limit:\n",
    "            print(\"Reached the last page. Stopping...\")\n",
    "            break\n",
    "\n",
    "        offset += limit\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        break\n",
    "\n",
    "# Save to JSON file\n",
    "json_string = json.dumps(all_results, indent=4)\n",
    "json_file_path = \"your-json-file.json\"  # Replace with your desired file name\n",
    "mssparkutils.fs.put(f\"your lakehouse path{json_file_path}\", json_string, True)\n",
    "print(\"Data saved to lakehouse\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea451e5-0bfe-4a53-8437-d1f4e8646ec7",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-03-25T08:59:25.202998Z",
       "execution_start_time": "2025-03-25T08:59:24.4597111Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "1f1b0f64-04d0-4615-b5c9-dcb2548b91fb",
       "queued_time": "2025-03-25T08:51:29.7693654Z",
       "session_id": "24136ad8-6b10-4a99-9846-8ee78b19a7d5",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 4,
       "statement_ids": [
        4
       ]
      },
      "text/plain": [
       "StatementMeta(, 24136ad8-6b10-4a99-9846-8ee78b19a7d5, 4, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Allow': 'GET, HEAD, OPTIONS', 'Content-Encoding': 'gzip', 'Content-Language': 'en', 'Content-Type': 'application/json', 'Date': 'Tue, 25 Mar 2025 08:59:10 GMT', 'Vary': 'Accept-Encoding, Accept, Accept-Language, Origin', 'transfer-encoding': 'chunked', 'Connection': 'keep-alive'}\n",
      "401\n"
     ]
    }
   ],
   "source": [
    "print(response.headers)\n",
    "response = requests.head(\"https://api.vainu.io/api/v2/companies/\")\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fd31ee-f636-4660-a7b3-8a617d3dbd38",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Financial data separately due to response overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239e42b-c21b-4cdb-a194-7b0b1d4203bb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-03-25T09:01:26.3888217Z",
       "execution_start_time": "2025-03-25T08:59:25.2055808Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "923f70dd-7091-4c85-835c-d04c31aca39b",
       "queued_time": "2025-03-25T08:51:29.7700699Z",
       "session_id": "24136ad8-6b10-4a99-9846-8ee78b19a7d5",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 5,
       "statement_ids": [
        5
       ]
      },
      "text/plain": [
       "StatementMeta(, 24136ad8-6b10-4a99-9846-8ee78b19a7d5, 5, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API request 1 took 0.87 seconds\n",
      "Fetched 1000 companies, total so far: 1000\n",
      "API request 2 took 1.92 seconds\n",
      "Fetched 1000 companies, total so far: 2000\n",
      "API request 3 took 4.47 seconds\n",
      "Fetched 1000 companies, total so far: 3000\n",
      "API request 4 took 7.23 seconds\n",
      "Fetched 1000 companies, total so far: 4000\n",
      "API request 5 took 12.17 seconds\n",
      "Fetched 1000 companies, total so far: 5000\n",
      "API request 6 took 15.36 seconds\n",
      "Fetched 1000 companies, total so far: 6000\n",
      "API request 7 took 23.65 seconds\n",
      "Fetched 1000 companies, total so far: 7000\n",
      "API request 8 took 19.75 seconds\n",
      "Fetched 1000 companies, total so far: 8000\n",
      "API request 9 took 24.36 seconds\n",
      "Fetched 562 companies, total so far: 8562\n",
      "Reached the last page. Stopping...\n",
      "Data saved to lakehouse\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "import pandas as pd\n",
    "\n",
    "#spark.conf.set(\"spark.network.timeout\", \"10000s\")  # Increase Spark network timeout\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"VainuAPI\").getOrCreate()\n",
    "\n",
    "# Microsoft Fabric Configuration\n",
    "key_vault_url = 'your-keyvault-url'  # Replace with your Key Vault URL\n",
    "secret_name = 'your-secret-name'  # Replace with your secret name\n",
    "\n",
    "API_KEY = notebookutils.credentials.getSecret(key_vault_url, secret_name)\n",
    "\n",
    "# Vainu API Endpoint\n",
    "API_URL = \"https://api.vainu.io/api/v2/companies/\"\n",
    "\n",
    "\n",
    "# Query variables for fina\n",
    "cities = [\"helsinki\", \"tampere\", \"vantaa\", \"espoo\", \"oulu\", \"turku\", \"lahti\", \"jyv채skyl채\"]\n",
    "queryfields_fina = \"business_id,total_funding_usd,financial_statements.year,financial_statements.turn_over_eur,financial_statements.profit,financial_statements.employee_salary_local,financial_statements.net_income_local\"\n",
    "offset = 0              # beginning point of query\n",
    "limit = 1000            # max limit\n",
    "staff_number_gt = 9     # staff number more than\n",
    "turn_over_gte = 500000  # turnover more than\n",
    "all_results = []\n",
    "i = 1\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"API-Key\": API_KEY,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "\n",
    "# Financial data GET loop\n",
    "while True:\n",
    "\n",
    "    params_fina = {\n",
    "    \"country\": \"FI\",\n",
    "    \"city\": cities,\n",
    "    \"fields\": queryfields_fina,\n",
    "    \"limit\": limit,\n",
    "    \"staff_number__gt\": staff_number_gt,\n",
    "    \"turn_over__gte\": turn_over_gte,\n",
    "    \"offset\": offset\n",
    "    }\n",
    "\n",
    "\n",
    "    time.sleep(1)   \n",
    "    start_time = time.time()\n",
    "    response = requests.get(API_URL, headers=headers, params=params_fina)\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"API request {i} took {duration:.2f} seconds\")\n",
    "    i += 1\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        results = data.get(\"results\", [])\n",
    "\n",
    "        if not results:\n",
    "            print(\"No more data to fetch. Stopping...\")\n",
    "            break\n",
    "\n",
    "        all_results.extend(results)\n",
    "\n",
    "        print(f\"Fetched {len(results)} companies, total so far: {len(all_results)}\")\n",
    "\n",
    "        if len(results) < limit:\n",
    "            print(\"Reached the last page. Stopping...\")\n",
    "            break\n",
    "\n",
    "        offset += limit\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        break\n",
    "\n",
    "# Save to JSON file\n",
    "json_string = json.dumps(all_results, indent=4)\n",
    "json_file_path = \"your-json-file.json\"  # Replace with your desired file name\n",
    "mssparkutils.fs.put(f\"your lakehouse path/{json_file_path}\", json_string, True)\n",
    "print(\"Data saved to lakehouse\")\n"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "20ac94e1-675c-4a9f-bf60-e8b533f17c6a",
    "default_lakehouse_name": "lead_generator_lakehouse",
    "default_lakehouse_workspace_id": "3d31ea41-b9d1-43a4-ae29-ba7ffc73a4fd"
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
